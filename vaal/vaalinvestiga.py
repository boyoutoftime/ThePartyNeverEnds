# archivo: arxiv_descargador.py

import urllib.request
import re
import os
import time

# Subcategor√≠as cient√≠ficas
subcategorias = [
    "astro-ph", "cond-mat", "gr-qc", "hep-ex", "hep-lat", "hep-ph",
    "hep-th", "math-ph", "nlin", "nucl-ex", "nucl-th", "physics", "quant-ph"
]

# Crear carpeta si no existe
os.makedirs("pdfs", exist_ok=True)

def descargar_pdf(abs_id, subcat):
    pdf_url = f"https://arxiv.org/pdf/{abs_id}.pdf"
    archivo_local = f"pdfs/{subcat}_{abs_id}.pdf"
    try:
        print(f"‚¨áÔ∏è Descargando PDF: {pdf_url}")
        urllib.request.urlretrieve(pdf_url, archivo_local)
        print(f"‚úÖ Guardado como: {archivo_local}")
    except Exception as e:
        print(f"‚ùå Error al descargar {pdf_url}: {e}")

def procesar_subcategoria(subcat):
    url = f"https://arxiv.org/list/{subcat}/recent"
    print(f"\nüîé Visitando: {url}")

    try:
        with urllib.request.urlopen(url) as response:
            html = response.read().decode("utf-8")
    except Exception as e:
        print(f"‚ùå Error al abrir {url}: {e}")
        return

    # Buscar todos los ID del tipo arXiv:2406.00493
    ids = re.findall(r'href="/abs/(\d{4}\.\d{5})"', html)

    if not ids:
        print("‚ö†Ô∏è No se encontraron art√≠culos recientes.")
        return

    # Eliminar duplicados (por si se repiten)
    ids = list(dict.fromkeys(ids))
    print(f"üìÑ Art√≠culos encontrados: {len(ids)}")

    # Descargar el primero
    for abs_id in ids[:1]:
        descargar_pdf(abs_id, subcat)
        time.sleep(2)

# Ejecutar sobre todas las subcategor√≠as
for subcat in subcategorias:
    procesar_subcategoria(subcat)